\chapter{評価}
本章では，全章で提案したヘッドノードにおけるフレーム処理並列化の有効性を確認するため，ヘッドノード内に構築したコンテナ環境において実験を行う．
実験1では，提案手法は既存手法と比較してヘッドノード内でのフレーム処理時間が短縮されているかを確認する．
実験2では，提案手法を用いたマルチディスプレイシステムに対して接続ディスプレイ数を変化させた場合のフレーム処理時間の変化を確認する．
さらに，実験3では，ヘッドノード内で分割コンテナ・圧縮コンテナを動かすにあたり，コンテナの起動と終了に要する時間の測定を行い，コンテナ環境でプロセスを動作させる際のオーバーヘッドについて調べる．
また，実験4では既存手法を用いて構築したマルチディスプレイシステムにおいて全てのノードでコンテナ環境を用意し，完全にコンテナ化されたマルチディスプレイシステムを構築した際のフレームレートについて調査する．
本章では，まず4.1節で，評価で利用した実験環境について説明する．次に，4.2節で，実験1における実験方法と実験結果について述べ，4.3節では，実験2における実験方法と実験結果を述べる．さらに，4.4章では実験3における実験方法と実験結果について述べ，最後に4.5章では実験4に用いた環境とフレームレートの計測結果を示す．

\section{実験環境}
本節では，実験1で用いた実験環境とその方法・結果について述べる．
実験1では，4つのディスプレイを接続して構築した4面構成のマルチディスプレイシステムを想定した実験を行った．
本実験で用いたヘッドノード内のコンテナ構成を図4.2に示す．

当実験環境は，ヘッドノードとして用いるデスクトップPC内のコンテナ仮想環境を用いて構築したものである．
実験環境内では1つの分割コンテナと複数の圧縮コンテナを用意する．
今回の実験では4面構成のディスプレイを想定しているため，ヘッドノード内では1つの分割コンテナと4つの圧縮コンテナを動作させた．

\begin{table}[H]
    \caption{ヘッドノード用デスクトップPCの仕様}
    \begin{center}
    \begin{tabular}{cc}
    \hline
    要素 & 仕様 \\\hline\hline
    CPU & i7-5960X (3.0 GHz×8) \\ \hline
    メモリ & 64.0 GB \\ \hline
    通信帯域 & 1 Gbps \\ \hline
    OS & CentOS 7.3 \\ \hline

    \end{tabular}
    \end{center}
\end{table}

評価に用いる映像としては，クリエイティブ・コモンズ・ライセンスのもとで利用できる3DアニメーションであるBig Buck Bunny \cite{bigbackbunny}を使用した．
表4.4に，Big Buck Bunnyのプロパティを示す．
さらに，図4.3にBig Buck Bunny再生時のスクリーンショットを示す．

\begin{table}[H]
    \caption{Big Buck Bunnyのプロパティ}
    \begin{center}
    \begin{tabular}{cc}
    \hline
    項目 & 内容 \\\hline\hline
    動画形式　& MP4 \\ \hline
    コーデック & H.264 \cite{h264} \\ \hline
    長さ & 10分34秒 \\ \hline
    総フレーム数 & 19020枚 \\ \hline
    フレームレート & 30 fps \\ \hline
    解像度 & 4K (3840×2160) \\ \hline

    \end{tabular}
    \end{center}
\end{table}

\begin{figure}[H]
    \hspace*{\fill}
    \includegraphics[width=\linewidth]{./fig/chap4/bigbuckbunny.eps}
    \hspace*{\fill}
    \caption{Big Buck Bunnyのスクリーンショット}
   \end{figure}

ヘッドノードで行われる処理の実装には，OpenCV \cite{opencv}, libjpeg-turbo ~\cite{libjpeg}, Boost.Asio \cite{asio}，gstreamer \cite{gstreamer} という4種類のライブラリを利用した． 
OpenCVは画像処理ライブラリ，libjpeg-turboはJPEGの圧縮と展開を行うライブラリ，Boost.Asioはソケット通信を行うライブラリであり，gstreamerはオープンソースのマルチメディアフレームワークである．
また，ディスプレイノードの処理の実装にはlibjpeg-turbo, Boost.Asio, fbdevを利用した．
実装にはC++言語を使用し，GCCコンパイラ (GNU C Compiler) \cite{gcc}でコンパイルを行った．


\begin{table}[H]
    \caption{評価で利用したソフトウェア}
    \begin{center}
    \begin{tabular}{cc}
    \hline
    ソフトウェア名 & バージョン \\\hline\hline
    OpenCV & 3.4.5/ \\ \hline
    Boost.Asio \cite{h264} & 1.53  \\ \hline
    FFMPEG & 2.8.17 \\ \hline
    libjpeg-turbo & 2.0.1 \\ \hline
    Gstreamer & 1.16.1 \\ \hline
    GCC & 8.5.0 \\ \hline

    \end{tabular}
    \end{center}
\end{table}


\begin{figure}[H]
    \hspace*{\fill}
    \includegraphics[width=\linewidth]{./fig/chap4/evaluation_environment.eps}
    \hspace*{\fill}
    \caption{実験環境のコンテナ構成}
   \end{figure}

\section{実験1:フレーム処理時間の評価}

\subsection{実験方法}
先行研究で提案された手法と提案手法において，4面構成のMDを想定した環境で4K解像度の画像を表示し，動画のフレーム開始から1000フレーム目の処理が終了するまでの1フレームあたりに要するフレーム処理時間を計測した．
また，フレーム処理時間の計測にはC++11の時間ライブラリであるchronoを用いた．
図4.6に先行研究で提案されたシステムと提案手法でのフレーム処理時間を示す．

\subsection{実験結果}


既存手法ではヘッドノードでのフレーム処理時間の平均が52.35msであったのに対し，提案手法では21.72msとなっており，フレーム処理時間が既存手法と比較して40\%程度まで短縮された事が確認できた．

また，本提案で新たに生じた処理である共有メモリを用いたプロセス間での画像フレームデータ受け渡しに要する時間も平均で1ms未満となっており，オーバーヘッドは非常に小さくなっていることも確認できる．

以上の結果より，フレーム処理プロセスの並列化を行った提案手法によって，システムのボトルネックが解消された．

\begin{figure}[H]
    \hspace*{\fill}
    \includegraphics[width=\linewidth]{./fig/chap4/processing_time_4.eps}
    \hspace*{\fill}
    \caption{フレーム処理時間の比較 (4面構成時)}
\end{figure}

\begin{figure}[H]
    \hspace*{\fill}
    \includegraphics[width=\linewidth]{./fig/chap4/processing_time_9.eps}
    \hspace*{\fill}
    \caption{フレーム処理時間の比較 (9面構成時)}
\end{figure}

\section{コンテナの起動時間に関する評価}
本節では，

\section{CPU使用率に関する評価}
\section{MDのコンテナ化の評価}
本節では，マルチディスプレイシステムのコンテナ化を行った実験について記す．


\subsection{実験方法}


\subsection{実験結果}

\begin{figure}[H]
    \hspace*{\fill}
    \includegraphics[width=\linewidth]{./fig/chap4/framerate_docker.eps}
    \hspace*{\fill}
    \caption{フレームレートの時間変化}
\end{figure}



\subsection{結果に対する考察}